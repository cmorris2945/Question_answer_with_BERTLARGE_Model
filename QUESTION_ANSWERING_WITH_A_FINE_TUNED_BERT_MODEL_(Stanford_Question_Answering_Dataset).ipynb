{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QUESTION ANSWERING WITH A FINE TUNED BERT MODEL (Stanford Question Answering Dataset).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "44c87bb12faf405e84379762b31eef70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_436e14b565d64b1fb38c25aec5bdf892",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4e7943a0ccdb4f5e93f281439b823b82",
              "IPY_MODEL_4deb7a2621e44f4ab7994b58aa2596a6",
              "IPY_MODEL_4cbce719d4c84e4597e4191b9dc0c694"
            ]
          }
        },
        "436e14b565d64b1fb38c25aec5bdf892": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4e7943a0ccdb4f5e93f281439b823b82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2ac77030a2f7401a851a3f1354058350",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d922727d6e774aaf886960dbef89c70f"
          }
        },
        "4deb7a2621e44f4ab7994b58aa2596a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5822613db48a4a77ac84ec7e21665d97",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 443,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 443,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_70fe8d9531394ea8b238f20c886874c6"
          }
        },
        "4cbce719d4c84e4597e4191b9dc0c694": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_efc5359fb0204d4ebca20e91923f684f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 443/443 [00:00&lt;00:00, 9.42kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0417b8403c8249cc9f5c13d06acb9734"
          }
        },
        "2ac77030a2f7401a851a3f1354058350": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d922727d6e774aaf886960dbef89c70f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5822613db48a4a77ac84ec7e21665d97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "70fe8d9531394ea8b238f20c886874c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "efc5359fb0204d4ebca20e91923f684f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0417b8403c8249cc9f5c13d06acb9734": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "255a30fb079247869f44ff86615bffe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_929abfef505e425c924ce82bd1e82559",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dc2c09e9f9e34e3b996c9035c2e7da16",
              "IPY_MODEL_969c40ea8ce14b7990e18a50d1ba91f2",
              "IPY_MODEL_036b1166a826414b88b0a95dd2158fc6"
            ]
          }
        },
        "929abfef505e425c924ce82bd1e82559": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dc2c09e9f9e34e3b996c9035c2e7da16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6bb3b55300f54fe7af36f0d9d7290da3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_abaeda1d9a3d434daed8b7d65a0918f2"
          }
        },
        "969c40ea8ce14b7990e18a50d1ba91f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9a7410932ce24e2cb7b5609926ddbf97",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2eeee8e4dd064c388780d4b284b52687"
          }
        },
        "036b1166a826414b88b0a95dd2158fc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_df667988a7934b43a43f85923e3affc1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226k/226k [00:00&lt;00:00, 368kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_00748b8be0274ecc8f5d9188a5181e11"
          }
        },
        "6bb3b55300f54fe7af36f0d9d7290da3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "abaeda1d9a3d434daed8b7d65a0918f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a7410932ce24e2cb7b5609926ddbf97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2eeee8e4dd064c388780d4b284b52687": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df667988a7934b43a43f85923e3affc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "00748b8be0274ecc8f5d9188a5181e11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_G9A8mJy0iv",
        "outputId": "c8abb1d6-789f-44a5-91de-a91f41c110ba"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 22.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 27.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 3.2 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 42.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.19 pyyaml-5.4.1 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0HgaJA8y8lN"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "44c87bb12faf405e84379762b31eef70",
            "436e14b565d64b1fb38c25aec5bdf892",
            "4e7943a0ccdb4f5e93f281439b823b82",
            "4deb7a2621e44f4ab7994b58aa2596a6",
            "4cbce719d4c84e4597e4191b9dc0c694",
            "2ac77030a2f7401a851a3f1354058350",
            "d922727d6e774aaf886960dbef89c70f",
            "5822613db48a4a77ac84ec7e21665d97",
            "70fe8d9531394ea8b238f20c886874c6",
            "efc5359fb0204d4ebca20e91923f684f",
            "0417b8403c8249cc9f5c13d06acb9734"
          ]
        },
        "id": "CwEkURU2y8p7",
        "outputId": "3f5f69b3-4bc4-459c-b08c-f1e5ce0864bc"
      },
      "source": [
        "from transformers import BertForQuestionAnswering\n",
        "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44c87bb12faf405e84379762b31eef70",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/443 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc2db72275564b6e9efd8ed61ae6c7c4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.25G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TggQadfoy8sO"
      },
      "source": [
        "#### LOAD THE TOKENIZER\n",
        "from transformers import BertTokenizer"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "255a30fb079247869f44ff86615bffe8",
            "929abfef505e425c924ce82bd1e82559",
            "dc2c09e9f9e34e3b996c9035c2e7da16",
            "969c40ea8ce14b7990e18a50d1ba91f2",
            "036b1166a826414b88b0a95dd2158fc6",
            "6bb3b55300f54fe7af36f0d9d7290da3",
            "abaeda1d9a3d434daed8b7d65a0918f2",
            "9a7410932ce24e2cb7b5609926ddbf97",
            "2eeee8e4dd064c388780d4b284b52687",
            "df667988a7934b43a43f85923e3affc1",
            "00748b8be0274ecc8f5d9188a5181e11"
          ]
        },
        "id": "pfTx6WeZy8u7",
        "outputId": "59608f6f-5b94-40ed-f68b-27434fda50eb"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "255a30fb079247869f44ff86615bffe8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "219d97680c29448b819601052f3e40eb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc72cf91c5d34a13ab3a85a58f5aa774",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csNn5Jq1y8xW"
      },
      "source": [
        "#### TIME TO TEST THE MODEL, AND ASK BERT A QUESTION...\n",
        "\n",
        "question= \"How many parameters does BERT-large have?\"\n",
        "\n",
        "answer_text = \"BERT-large is really big...it has 24-layers and an embedding size of 1,024, for a total of 340M parameters!\"\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLLTo7M5y8zb",
        "outputId": "f5dd78f6-f5fb-40a5-a46b-0fc0e7665d11"
      },
      "source": [
        "## WE HAVE TO RUN BERT TOKENIZER AGAINST BOTH QUESTION AND answer_text.\n",
        "# TO FEED THEM INTO BERT, WE ACTUALLY CONCATENATE THEM.\n",
        "### APPLY THE TOKENIZER TO THE INPUT TEXT, TREATING THEM AS A TEXT-PAIR###\n",
        "\n",
        "input_ids = tokenizer.encode(question, answer_text)\n",
        "\n",
        "print(\"The input has a  total of {:} tokens.\".format(len(input_ids)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input has a  total of 46 tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KE5JhT52y82D",
        "outputId": "6222789c-d616-4774-f510-8f31c8c1cb40"
      },
      "source": [
        "## I WILL NOW PRINT OUT ALL THE TOKENS AND THEIR ID NUMBERS.\n",
        "\n",
        "## BERT NEEDS ONLY THE TOKEN ID'S, BUT FOR THE PURPOSE OF INSPECTING THE\n",
        "## TOKENIZER'S BEHAVIOR, LET'S ALSO GET THE TOKEN STRINGS AND DISPLAY THEM....\n",
        "\n",
        "tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "\n",
        "## For each token and its id....\n",
        "for token, id in zip(tokens, input_ids):\n",
        "\n",
        "   ## \n",
        "  if id == tokenizer.sep_token_id:\n",
        "    print('')\n",
        "\n",
        "  ##PRINT THE TOKEN STRING AND ITS ID IN TWO COLUMNS...\n",
        "\n",
        "  print('{:<12} {:>6,}'.format(token, id))\n",
        "\n",
        "  if id == tokenizer.sep_token_id:\n",
        "    print('')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]           101\n",
            "how           2,129\n",
            "many          2,116\n",
            "parameters   11,709\n",
            "does          2,515\n",
            "bert         14,324\n",
            "-             1,011\n",
            "large         2,312\n",
            "have          2,031\n",
            "?             1,029\n",
            "\n",
            "[SEP]           102\n",
            "\n",
            "bert         14,324\n",
            "-             1,011\n",
            "large         2,312\n",
            "is            2,003\n",
            "really        2,428\n",
            "big           2,502\n",
            ".             1,012\n",
            ".             1,012\n",
            ".             1,012\n",
            "it            2,009\n",
            "has           2,038\n",
            "24            2,484\n",
            "-             1,011\n",
            "layers        9,014\n",
            "and           1,998\n",
            "an            2,019\n",
            "em            7,861\n",
            "##bed         8,270\n",
            "##ding        4,667\n",
            "size          2,946\n",
            "of            1,997\n",
            "1             1,015\n",
            ",             1,010\n",
            "02            6,185\n",
            "##4           2,549\n",
            ",             1,010\n",
            "for           2,005\n",
            "a             1,037\n",
            "total         2,561\n",
            "of            1,997\n",
            "340          16,029\n",
            "##m           2,213\n",
            "parameters   11,709\n",
            "!               999\n",
            "\n",
            "[SEP]           102\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmACG5L-y84k"
      },
      "source": [
        "### search the iput ids for the first instance of the '[SEP]' token...\n",
        "\n",
        "\n",
        "sep_index = input_ids.index(tokenizer.sep_token_id)\n",
        "\n",
        "\n",
        "# the number of segment 'A' tokens includes the [SEP] token itself...\n",
        "\n",
        "num_seg_A = sep_index +1\n",
        "\n",
        "## the remainder are the segment 'B'...\n",
        "\n",
        "num_seg_B = len(input_ids) - num_seg_A\n",
        "\n",
        "##  Construct the list of 0s and 1s...\n",
        "segment_ids = [0]*num_seg_A+ [1]*num_seg_B\n",
        "\n",
        "\n",
        "## there should be a segment_id for every input token....\n",
        "\n",
        "\n",
        "assert len(segment_ids) == len(input_ids)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHk2i8xwAna9"
      },
      "source": [
        "### WE ARE NOT USING ANY PADDING. ITS FOR BATCH PROCESSING SETENCES ALL AT ONCE....\n",
        "\n",
        "\n",
        "# run our example thorugh the model:\n",
        "\n",
        "\n",
        "start_scores, end_scores = model(torch.tensor([input_ids]),  #the tokens representing our input text\n",
        "                                 token_type_ids = torch.tensor([segment_ids]))  # the segment ids to differenetiate the questions"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec9C8Mms71GE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMb5dSn9AndX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "2d85d10c-c61a-4db6-a91a-ae7ccaf9c791"
      },
      "source": [
        "### NOW WE CAN HIGHLIGHT THE ANSWER JUST BY LOOKIG AT THE MOST PROBABLE START AND END WORDS\n",
        "\n",
        "### Find the tokens with the highest 'start' and 'end' scores...\n",
        "\n",
        "answer_start = torch.argmax(start_scores)\n",
        "answer_end = torch.argmax(end_scores)\n",
        "\n",
        "## Combine the tokens in the answer and print it out...\n",
        "\n",
        "answer = ' '.join(tokens[answer_start:answer_end+1])\n",
        "\n",
        "print(('Answer: \"' + answer + '\"'))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-ee7c2803aa95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m### Find the tokens with the highest 'start' and 'end' scores...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0manswer_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0manswer_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: argmax(): argument 'input' (position 1) must be Tensor, not str"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIByXwHrAngH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "48c19611-7ad0-457e-ea2d-d3d734f6e52c"
      },
      "source": [
        "## RECONSTRUCT ANY WORD THAT GETS BROKEN DOWN INTO SUB WORDS\n",
        "\n",
        "\n",
        "# start with the first token:\n",
        "\n",
        "answer = tokens[answer_start]\n",
        "\n",
        "## Select the remaining answer tokens and join them with whitespace:\n",
        "\n",
        "for i in range(answer_start +1, answer_end +1):\n",
        "\n",
        "  ## If it's a subword token, then recombine it with the previous token:\n",
        "\n",
        "  if tokens[i][0:2] == '##':\n",
        "    answer += tokens[i][2:]\n",
        "\n",
        "  else:\n",
        "    answer += ' ' + tokens[i]\n",
        "\n",
        "print('Answer: \"' + answer + '\"' )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-5ca5d61c340b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# start with the first token:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0manswer_start\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m## Select the remaining answer tokens and join them with whitespace:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'answer_start' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRe-2HPDAnii"
      },
      "source": [
        "\n",
        "## WE CAN VISUALIZE THE SCORES TO SEE WHAT THE MODEL IS PRODUCING>>>\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn\n",
        "\n",
        "sns.set(style= 'darkgrid')\n",
        "\n",
        "# Increase the plot size and the font size\n",
        "\n",
        "# sns set(font_scale = 1.5)\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (16,8)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZGTBmDfAnlO"
      },
      "source": [
        "# pull the scores out of Pytorch Tesors and convert them to 1D arrays...\n",
        "\n",
        "s_scores= start_scores.detach().numpy().flatten()\n",
        "\n",
        "e_scores= end_scores.detach().numpy().flatten()\n",
        "\n",
        "# We'll use the tokens so the x-axis labels. In order to do that,\n",
        "# they all need to be unique, so we'll add the token index to the end of each one\n",
        "\n",
        "token_labels = []\n",
        "\n",
        "for (i,token) in enumerate(tokens):\n",
        "  token_labels.append('{:} - {:>2}'.format(token,i))\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtI4WGM5AnnY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "aeaecf5e-8169-409e-a7cc-02e8bcefd081"
      },
      "source": [
        "## CREATE A BAR PLOT SHOWING THE SCORE OF EVERY INPUT WORD BEING THE START WORD:\n",
        "\n",
        "\n",
        "ax = sns.barplot(x=token_labels, y = s_scores, ci = None)\n",
        "\n",
        "#Turn the xlabels vertical\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha = \"center\")\n",
        "\n",
        "# Turn on the vertical grid to help align words to scores...\n",
        "ax.grid(True)\n",
        "\n",
        "plt.title('Start Word Scores')\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-1cbe67c6e870>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mci\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#Turn the xlabels vertical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPVTt55dAnpw"
      },
      "source": [
        "### CREATE A BARPLOT SHOWING THE END WORD SCORES FOR ALL OF THE TOKENS...\n",
        "\n",
        "\n",
        "ax = sns.barplot(x=token_labels, y = e_scores, ci = None)\n",
        "\n",
        "# Turn the xlabels vertical....\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation= 90, ha= \"center\")\n",
        "\n",
        "#Turn on the vertical grid to help words to scores....\n",
        "\n",
        "ax.grid(True)\n",
        "\n",
        "plt.title\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-B2zA-vAnsV"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "# store the tokens in a dataframe....\n",
        "\n",
        "\n",
        "scores = []\n",
        "\n",
        "for (i, token_label) in enumerate(token_labels):\n",
        "## add the tokens start scores as one row\n",
        "  scores.append({'token_label': token_label,\n",
        "                 'score': s_scores[i],\n",
        "                 'marker': 'start'})\n",
        "  \n",
        "  # Add the tokes end ecore as another row:\n",
        "\n",
        "  scores.append({'token_label': token_label},\n",
        "                'score': e_scores[i],\n",
        "                'marker': 'end'})\n",
        "  \n",
        "df = pd.DataFrame(scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cT3flaSa8Tn"
      },
      "source": [
        "## Draw a groped barplot to show start and end scores for each\n",
        "#word. The hue parameter is where we tell it which datapoints belong\n",
        "# to which of the two series...\n",
        "\n",
        "\n",
        "\n",
        "g = sns.catplot(x=\"token_label\", y = \"score\", hue = \"marker\", data= df,\n",
        "                kind = \"bar\", height = 6, aspect = 4)\n",
        "\n",
        "\n",
        "# Turn the xlabels vertical...\n",
        "\n",
        "g.set_xticklabels(g.ax.get_xticklabels(), rotation = 90, ha = \"center\")\n",
        "\n",
        "# the on the vertical grid to help align the words to scores...\n",
        "\n",
        "g.ax.grid(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdA9ugyca8Vr"
      },
      "source": [
        "### Function that does everything....\n",
        "\n",
        "def answer_question(question, answer_text):\n",
        "\n",
        "  '''Takes a question string, and an answer text string (which contains the answer\n",
        "  ), and identifies the words within the answer_text that are the answer. \n",
        "  Prints them out).'''\n",
        "\n",
        "\n",
        "  ##=======TOKENIZE ======\n",
        "\n",
        "    ## apply the tokenizer to the input text, treating them as a text-pair.\n",
        "\n",
        "    input_ids = tokenizer.encode(question, answer_text)\n",
        "\n",
        "    # Report how long the input sequence is:\n",
        "\n",
        "    print('Query has {:,} tokens.\\n'.format(len(input_ids)))\n",
        "\n",
        "\n",
        "    # =======Set Segment IDs ======\n",
        "    # Search the iput_ids for first instance of the [SEP] token...\n",
        "\n",
        "    sep_index = input_ids.index(tokenizer.sep_token_id)\n",
        "\n",
        "\n",
        "    # The number of segment A tokens includes the [SEP] token itself\n",
        "    num_seg_A = sep_index + 1\n",
        "\n",
        "\n",
        "    #  The remainder are the segment B...\n",
        "    num_seg_B = len(input_ids) - num_seg_A\n",
        "\n",
        "    ## Construct the list of 0's and 1's\n",
        "\n",
        "\n",
        "    segment_ids = [0]*num_seg_A + [1]*num_seg_B\n",
        "\n",
        "    # There should be a segment_id for every input token...\n",
        "\n",
        "    assert len(segment_ids) == len(input_ids)\n",
        "\n",
        "\n",
        "\n",
        "    # =====EVALUATE =====\n",
        "\n",
        "    #Run the example question through the model...\n",
        "\n",
        "    start_scores, end_scores = model(torch.tensor([input_ids],\n",
        "                                                  token_type_ids = torch.tensor([segment_ids]))\n",
        "    \n",
        "\n",
        "    ### ========RECONSTRUCT ANSWER ======\n",
        "\n",
        "    # Find the tokens with the highest start and end scores...\n",
        "\n",
        "    answer_start = torch.argmax(start_scores)\n",
        "    answer_end = torch.argmax(end_scores)\n",
        "\n",
        "    # Get the string versions of the input tokens...\n",
        "\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "\n",
        "    # Start with the first token\n",
        "    answer = tokens[answer_start]\n",
        "\n",
        "    ## Select the remainign answer tokens and join them with whitespace....\n",
        "    for i in range(answer_start +1, answer_end +1):\n",
        "\n",
        "      # If its a subword, then recombine it with the previous token.\n",
        "\n",
        "      if tokens[i][0:2] == '##':\n",
        "        answer += tokens[i][2:]\n",
        "\n",
        "      # Otherwise add a space then the token...\n",
        "      else:\n",
        "        answer += ' ' + token[i]\n",
        "\n",
        "    print('Answer: \"' + answer + '\"')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44pnfpMSa8Xu"
      },
      "source": [
        "import textwrap\n",
        "# Wrap text to 80 characters...\n",
        "\n",
        "wrapper = textwrap.Textwrapper(width=80)\n",
        "\n",
        "bert_abstract = \"We introduce a new language representaion model called BERT, which stands for Bidirectional Encoder Representation Transformer\"\n",
        "\n",
        "print(wrapper.fill(bert_abstract))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lQayaQMa8Z3"
      },
      "source": [
        "#   QUESTION TIME ####\n",
        "\n",
        "question = \"What does the 'B' is BERT stand for?\"\n",
        "\n",
        "answer_question(question, bert_abstract)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0Tx4TCka8bq"
      },
      "source": [
        "question = \"What are some example applications of BERT??\"\n",
        "\n",
        "\n",
        "answer_question(question, bert_abstract)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}